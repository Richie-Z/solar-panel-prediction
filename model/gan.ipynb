{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN MODEL TRAINING\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import (\n",
    "    find_missing_date_ranges,\n",
    ")\n",
    "\n",
    "from gan import (build_generator, build_discriminator, SolarGAN)\n",
    "\n",
    "from enums import (\n",
    "    DatasetColumns,\n",
    "    WeatherDatasetColumns\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "FILE_NAME = \"dataset.csv\"\n",
    "WEATHER_DATASET = \"dataset_weather.csv\"\n",
    "\n",
    "\n",
    "original_data = pd.read_csv(\n",
    "    FILE_NAME,\n",
    "    parse_dates=[DatasetColumns.STATISTICAL_PERIOD.value],\n",
    "    index_col=DatasetColumns.STATISTICAL_PERIOD.value,\n",
    ")\n",
    "\n",
    "\n",
    "weather_data = pd.read_csv(\n",
    "    WEATHER_DATASET,\n",
    "    parse_dates=[WeatherDatasetColumns.DATETIME.value],\n",
    "    index_col=WeatherDatasetColumns.DATETIME.value,\n",
    ").asfreq(\"h\")\n",
    "\n",
    "weather_features = [\n",
    "    WeatherDatasetColumns.TEMPERATURE_C.value,\n",
    "    WeatherDatasetColumns.HUMIDITY_PERCENT.value,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing date ranges\n",
    "gap_start, gap_end = find_missing_date_ranges(\n",
    "    original_data, DatasetColumns.STATISTICAL_PERIOD.value\n",
    ")\n",
    "gap_dates = pd.date_range(start=gap_start, end=gap_end, freq=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "pre_gap_data = original_data[original_data.index < gap_start].asfreq(\"h\")\n",
    "post_gap_data = original_data[original_data.index >= gap_end].asfreq(\"h\")\n",
    "\n",
    "pre_gap_train_size = int(len(pre_gap_data) * 0.8)\n",
    "pre_gap_train = pre_gap_data.iloc[:pre_gap_train_size].copy()\n",
    "pre_gap_test = pre_gap_data.iloc[pre_gap_train_size:]\n",
    "\n",
    "pre_gap_train.loc[:, DatasetColumns.PV_YIELD.value] = pre_gap_train[\n",
    "    DatasetColumns.PV_YIELD.value\n",
    "].interpolate(method=\"linear\")\n",
    "\n",
    "\n",
    "pre_weather_data = weather_data[weather_data.index < gap_start].bfill()\n",
    "pre_weather_data = pre_weather_data.reindex(pre_gap_data.index)\n",
    "pre_weather_data_test = pre_weather_data.reindex(pre_gap_test.index)\n",
    "\n",
    "\n",
    "gap_weather_data = weather_data.reindex(gap_dates).ffill()\n",
    "post_weather_data = weather_data[weather_data.index >= gap_end].bfill()\n",
    "\n",
    "\n",
    "pre_gap_train_combined = pre_gap_train.join(\n",
    "    pre_weather_data[weather_features], how=\"inner\"\n",
    ")\n",
    "pre_gap_test_combined = pre_gap_test.join(\n",
    "    pre_weather_data_test[weather_features], how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Hyperparameters\n",
    "LATENT_DIM = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(pre_gap_train_combined, pre_gap_test_combined, weather_features):\n",
    "    # Scale the data\n",
    "    combined_columns = [DatasetColumns.PV_YIELD.value] + weather_features\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit and transform training data\n",
    "    train_scaled = scaler.fit_transform(pre_gap_train_combined[combined_columns])\n",
    "    train_pv = train_scaled[:, 0:1].astype(np.float32)  # Convert to float32\n",
    "    train_weather = train_scaled[:, 1:].astype(np.float32)  # Convert to float32\n",
    "\n",
    "    # Transform test data\n",
    "    test_scaled = scaler.transform(pre_gap_test_combined[combined_columns])\n",
    "    test_pv = test_scaled[:, 0:1].astype(np.float32)\n",
    "    test_weather = test_scaled[:, 1:].astype(np.float32)\n",
    "\n",
    "    # Create TensorFlow datasets with float32 data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(train_pv, tf.float32), tf.cast(train_weather, tf.float32))\n",
    "    )\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(test_pv, tf.float32), tf.cast(test_weather, tf.float32))\n",
    "    )\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return train_dataset, test_dataset, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize training progress\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history[\"d_loss\"], label=\"Discriminator Loss\")\n",
    "    plt.plot(history[\"g_loss\"], label=\"Generator Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training History\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_solar_gan(train_dataset, num_features):\n",
    "    # Configure TensorFlow for metal\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(\n",
    "            tf.config.list_physical_devices(\"GPU\")[0], True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    solar_gan = SolarGAN(LATENT_DIM, num_features)\n",
    "\n",
    "    initial_lr = 2e-4  # Slightly reduced learning rate\n",
    "\n",
    "    solar_gan.compile(\n",
    "        g_optimizer=tf.keras.optimizers.Adam(initial_lr, beta_1=0.0, beta_2=0.9),\n",
    "        d_optimizer=tf.keras.optimizers.Adam(initial_lr, beta_1=0.0, beta_2=0.9),\n",
    "    )\n",
    "\n",
    "    history = {\"d_loss\": [], \"g_loss\": []}\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 50  # Reduced patience\n",
    "    patience_counter = 0\n",
    "    min_epochs = 300  # Reduced minimum epochs\n",
    "\n",
    "    warmup_epochs = 10  # Reduced warmup\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_d_loss = []\n",
    "        epoch_g_loss = []\n",
    "\n",
    "        if epoch < warmup_epochs:\n",
    "            current_lr = initial_lr * (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            current_lr = initial_lr * (0.98 ** (epoch - warmup_epochs))\n",
    "\n",
    "        solar_gan.g_optimizer = tf.keras.optimizers.Adam(\n",
    "            current_lr, beta_1=0.0, beta_2=0.9\n",
    "        )\n",
    "        solar_gan.d_optimizer = tf.keras.optimizers.Adam(\n",
    "            current_lr, beta_1=0.0, beta_2=0.9\n",
    "        )\n",
    "\n",
    "        for batch_data in train_dataset:\n",
    "            # Reduced discriminator steps\n",
    "            d_steps = 3 if np.mean(epoch_d_loss) > 5 else 2\n",
    "            for _ in range(d_steps):\n",
    "                losses = solar_gan.train_step(batch_data)\n",
    "                epoch_d_loss.append(float(losses[\"d_loss\"]))\n",
    "                epoch_g_loss.append(float(losses[\"g_loss\"]))\n",
    "\n",
    "        avg_d_loss = np.mean(epoch_d_loss)\n",
    "        avg_g_loss = np.mean(epoch_g_loss)\n",
    "\n",
    "        history[\"d_loss\"].append(avg_d_loss)\n",
    "        history[\"g_loss\"].append(avg_g_loss)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:  # More frequent updates\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{EPOCHS} | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}\"\n",
    "            )\n",
    "            print(f\"Current learning rate: {current_lr:.6f}\")\n",
    "\n",
    "        if epoch >= min_epochs:\n",
    "            current_loss = abs(avg_d_loss)\n",
    "            if current_loss < best_loss * 1.1:\n",
    "                best_loss = min(current_loss, best_loss)\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    return solar_gan, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "def generate_predictions(model, weather_features, scaler):\n",
    "    # Ensure weather_features is float32\n",
    "    weather_features = tf.cast(weather_features, tf.float32)\n",
    "    batch_size = tf.shape(weather_features)[0]\n",
    "\n",
    "    # Create noise input\n",
    "    noise = tf.random.normal([batch_size, LATENT_DIM], dtype=tf.float32)\n",
    "\n",
    "    # Generate predictions by passing noise and weather features separately\n",
    "    predictions_scaled = model.generator([noise, weather_features], training=False)\n",
    "\n",
    "    # Convert predictions to numpy and prepare for inverse transform\n",
    "    predictions_with_weather = np.concatenate(\n",
    "        [predictions_scaled.numpy(), weather_features.numpy()], axis=1\n",
    "    )\n",
    "    predictions = scaler.inverse_transform(predictions_with_weather)[:, 0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Example usage in evaluation\n",
    "def evaluate_model(model, test_dataset, scaler):\n",
    "    all_predictions = []\n",
    "    all_true_values = []\n",
    "\n",
    "    for test_pv, test_weather in test_dataset:\n",
    "        # Generate predictions for this batch\n",
    "        batch_predictions = generate_predictions(model, test_weather, scaler)\n",
    "\n",
    "        # Store predictions and true values\n",
    "        all_predictions.extend(batch_predictions)\n",
    "        all_true_values.extend(test_pv.numpy().flatten())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_true_values = np.array(all_true_values)\n",
    "\n",
    "    # Calculate metrics (e.g., MSE, MAE)\n",
    "    mse = np.mean((all_predictions - all_true_values) ** 2)\n",
    "    mae = np.mean(np.abs(all_predictions - all_true_values))\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "\n",
    "    return all_predictions, all_true_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pre_gap_data` training model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, scaler = prepare_data(\n",
    "        pre_gap_train_combined,\n",
    "        pre_gap_test_combined,\n",
    "        weather_features\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richie/.venv/dev/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/Users/richie/.venv/dev/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/richie/.venv/dev/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "2025-02-06 17:11:50.678557: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-06 17:12:04.949975: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-06 17:12:33.982864: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000 | D Loss: 7.6752 | G Loss: 0.4528\n",
      "Current learning rate: 0.000100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_weather_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weather_features)\n\u001b[0;32m----> 3\u001b[0m solar_gan, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_solar_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_weather_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plot_training_history(history)\n",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m, in \u001b[0;36mtrain_solar_gan\u001b[0;34m(train_dataset, num_features)\u001b[0m\n\u001b[1;32m     45\u001b[0m d_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(epoch_d_loss) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_steps):\n\u001b[0;32m---> 47\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43msolar_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     epoch_d_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(losses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     49\u001b[0m     epoch_g_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(losses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_weather_features = len(weather_features)\n",
    "solar_gan, history = train_solar_gan(train_dataset, num_weather_features)\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating model on test set...\")\n",
    "predictions, true_values = evaluate_model(solar_gan, test_dataset, scaler)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(true_values, label='True Values', marker='o')\n",
    "plt.plot(predictions, label='Predicted Values', marker='x')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('PV Yield')\n",
    "plt.legend()\n",
    "plt.title('True vs Predicted PV Yield (First 100 samples)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
