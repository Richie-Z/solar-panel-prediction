{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN MODEL TRAINING\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import (\n",
    "    find_missing_date_ranges,\n",
    "    evaluate_predictions,\n",
    "    compare_prediction\n",
    ")\n",
    "\n",
    "from gan import (build_generator, build_discriminator, SolarGAN)\n",
    "\n",
    "from enums import (\n",
    "    DatasetColumns,\n",
    "    WeatherDatasetColumns\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "FILE_NAME = \"dataset.csv\"\n",
    "WEATHER_DATASET = \"dataset_weather.csv\"\n",
    "\n",
    "\n",
    "original_data = pd.read_csv(\n",
    "    FILE_NAME,\n",
    "    parse_dates=[DatasetColumns.STATISTICAL_PERIOD.value],\n",
    "    index_col=DatasetColumns.STATISTICAL_PERIOD.value,\n",
    ")\n",
    "\n",
    "weather_data = pd.read_csv(\n",
    "    WEATHER_DATASET,\n",
    "    parse_dates=[WeatherDatasetColumns.DATETIME.value],\n",
    "    index_col=WeatherDatasetColumns.DATETIME.value,\n",
    ").asfreq(\"h\")\n",
    "\n",
    "weather_features = [\n",
    "    WeatherDatasetColumns.TEMPERATURE_C.value,\n",
    "    WeatherDatasetColumns.HUMIDITY_PERCENT.value,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing date ranges\n",
    "gap_start, gap_end = find_missing_date_ranges(\n",
    "    original_data, DatasetColumns.STATISTICAL_PERIOD.value\n",
    ")\n",
    "gap_dates = pd.date_range(start=gap_start, end=gap_end, freq=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "pre_gap_data = original_data[original_data.index < gap_start].asfreq(\"h\")\n",
    "post_gap_data = original_data[original_data.index >= gap_end].asfreq(\"h\")\n",
    "\n",
    "pre_gap_train_size = int(len(pre_gap_data) * 0.8)\n",
    "pre_gap_train = pre_gap_data.iloc[:pre_gap_train_size].copy()\n",
    "pre_gap_test = pre_gap_data.iloc[pre_gap_train_size:]\n",
    "\n",
    "pre_gap_train.loc[:, DatasetColumns.PV_YIELD.value] = pre_gap_train[\n",
    "    DatasetColumns.PV_YIELD.value\n",
    "].interpolate(method=\"linear\")\n",
    "\n",
    "\n",
    "pre_weather_data = weather_data[weather_data.index < gap_start].bfill()\n",
    "pre_weather_data = pre_weather_data.reindex(pre_gap_data.index)\n",
    "pre_weather_data_test = pre_weather_data.reindex(pre_gap_test.index)\n",
    "\n",
    "\n",
    "gap_weather_data = weather_data.reindex(gap_dates).ffill()\n",
    "post_weather_data = weather_data[weather_data.index >= gap_end].bfill()\n",
    "\n",
    "\n",
    "pre_gap_train_combined = pre_gap_train.join(\n",
    "    pre_weather_data[weather_features], how=\"inner\"\n",
    ")\n",
    "pre_gap_test_combined = pre_gap_test.join(\n",
    "    pre_weather_data_test[weather_features], how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Hyperparameters\n",
    "LATENT_DIM = 10\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(pre_gap_train_combined, pre_gap_test_combined, weather_features):\n",
    "    # Scale the data\n",
    "    combined_columns = [DatasetColumns.PV_YIELD.value] + weather_features\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit and transform training data\n",
    "    train_scaled = scaler.fit_transform(pre_gap_train_combined[combined_columns])\n",
    "    train_pv = train_scaled[:, 0:1]  # PV yield\n",
    "    train_weather = train_scaled[:, 1:]  # Weather features\n",
    "\n",
    "    # Transform test data\n",
    "    test_scaled = scaler.transform(pre_gap_test_combined[combined_columns])\n",
    "    test_pv = test_scaled[:, 0:1]\n",
    "    test_weather = test_scaled[:, 1:]\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_pv, train_weather))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_pv, test_weather))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return train_dataset, test_dataset, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_solar_gan(train_dataset, num_features):\n",
    "    # Build generator and discriminator\n",
    "    generator = build_generator(\n",
    "        input_dim=LATENT_DIM + num_features, output_dim=1  # PV yield output\n",
    "    )\n",
    "\n",
    "    discriminator = build_discriminator(\n",
    "        input_dim=1 + num_features  # PV yield + weather features\n",
    "    )\n",
    "\n",
    "    # Create WGAN model\n",
    "    solar_gan = SolarGAN(\n",
    "        latent_dim=LATENT_DIM,\n",
    "        feature_dim=num_features,\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    solar_gan.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=0.5, beta_2=0.9)\n",
    "    )\n",
    "\n",
    "    # Training history\n",
    "    history = {\"d_loss\": [], \"g_loss\": []}\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_d_loss = []\n",
    "        epoch_g_loss = []\n",
    "\n",
    "        for batch_data in train_dataset:\n",
    "            losses = solar_gan.train_step(batch_data)\n",
    "            epoch_d_loss.append(float(losses[\"d_loss\"]))\n",
    "            epoch_g_loss.append(float(losses[\"g_loss\"]))\n",
    "\n",
    "        # Average losses over the epoch\n",
    "        avg_d_loss = np.mean(epoch_d_loss)\n",
    "        avg_g_loss = np.mean(epoch_g_loss)\n",
    "\n",
    "        history[\"d_loss\"].append(avg_d_loss)\n",
    "        history[\"g_loss\"].append(avg_g_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{EPOCHS} | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    return solar_gan, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, weather_features, scaler):\n",
    "    batch_size = len(weather_features)\n",
    "    noise = tf.random.normal([batch_size, LATENT_DIM])\n",
    "    generator_inputs = tf.concat([noise, weather_features], axis=1)\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions_scaled = model.generator(generator_inputs, training=False)\n",
    "\n",
    "    # Prepare for inverse transform\n",
    "    predictions_with_weather = np.concatenate(\n",
    "        [predictions_scaled, weather_features], axis=1\n",
    "    )\n",
    "    predictions = scaler.inverse_transform(predictions_with_weather)[:, 0]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pre_gap_data` training model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, scaler = prepare_data(\n",
    "        pre_gap_train_combined,\n",
    "        pre_gap_test_combined,\n",
    "        weather_features\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richie/.venv/dev/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/richie/.venv/dev/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The layer Generator has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_weather_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weather_features)\n\u001b[0;32m----> 3\u001b[0m solar_gan, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_solar_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_weather_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mtrain_solar_gan\u001b[0;34m(train_dataset, num_features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_solar_gan\u001b[39m(train_dataset, num_features):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Build generator and discriminator\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLATENT_DIM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# PV yield output\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     discriminator \u001b[38;5;241m=\u001b[39m build_discriminator(\n\u001b[1;32m      8\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m num_features  \u001b[38;5;66;03m# PV yield + weather features\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Create WGAN model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mbuild_generator\u001b[0;34m(input_dim, output_dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(output_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\u001b[38;5;241m.\u001b[39mModel(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, x)\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/keras/src/ops/operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev/lib/python3.12/site-packages/keras/src/ops/operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The layer Generator has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_weather_features = len(weather_features)\n",
    "solar_gan, history = train_solar_gan(train_dataset, num_weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test set\n",
    "for test_pv, test_weather in test_dataset:\n",
    "    predictions = generate_predictions(solar_gan, test_weather, scaler)\n",
    "    # Store or evaluate predictions as needed\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history[\"d_loss\"], label=\"Discriminator Loss\")\n",
    "plt.plot(history[\"g_loss\"], label=\"Generator Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training History\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
